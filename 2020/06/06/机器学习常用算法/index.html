<!DOCTYPE html>
<html lang=en>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="[TOC]  线性回归 逻辑回归 决策树 支持向量机 朴素贝叶斯 神经网络 K均值 随机森林 降维算法 梯度提升算法   GBM XGBoost LightGBM catboost  1.线性回归1234567891011# 线性回归主要有两种类型：简单线性回归和多重线性回归。简单线性回归的特征在于一个独立变量。并且，多重线性回归（顾名思义）具有多个（大于1个）# 独立变量的特征。找到最佳拟合线时">
<meta name="keywords" content="algorithm,machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习常用算法">
<meta property="og:url" content="https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/index.html">
<meta property="og:site_name" content="Robby">
<meta property="og:description" content="[TOC]  线性回归 逻辑回归 决策树 支持向量机 朴素贝叶斯 神经网络 K均值 随机森林 降维算法 梯度提升算法   GBM XGBoost LightGBM catboost  1.线性回归1234567891011# 线性回归主要有两种类型：简单线性回归和多重线性回归。简单线性回归的特征在于一个独立变量。并且，多重线性回归（顾名思义）具有多个（大于1个）# 独立变量的特征。找到最佳拟合线时">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2020-06-28T13:02:27.186Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习常用算法">
<meta name="twitter:description" content="[TOC]  线性回归 逻辑回归 决策树 支持向量机 朴素贝叶斯 神经网络 K均值 随机森林 降维算法 梯度提升算法   GBM XGBoost LightGBM catboost  1.线性回归1234567891011# 线性回归主要有两种类型：简单线性回归和多重线性回归。简单线性回归的特征在于一个独立变量。并且，多重线性回归（顾名思义）具有多个（大于1个）# 独立变量的特征。找到最佳拟合线时">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>机器学习常用算法</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">Tag</a></li>
         
          <li><a href="/categories/">Category</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2020/06/23/06-缺失数据/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/06/02/05-零基础入门CV-模型集成/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&text=机器学习常用算法"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&is_video=false&description=机器学习常用算法"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=机器学习常用算法&body=Check out this article: https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&name=机器学习常用算法&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-线性回归"><span class="toc-number">1.</span> <span class="toc-text">1.线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-逻辑回归"><span class="toc-number">2.</span> <span class="toc-text">2. 逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#改进模型"><span class="toc-number">2.0.1.</span> <span class="toc-text">改进模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-决策树"><span class="toc-number">3.</span> <span class="toc-text">3. 决策树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-支持向量机"><span class="toc-number">4.</span> <span class="toc-text">4. 支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-朴素贝叶斯"><span class="toc-number">5.</span> <span class="toc-text">5. 朴素贝叶斯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-kNN-k最近邻"><span class="toc-number">6.</span> <span class="toc-text">6. kNN(k最近邻)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-k-均值"><span class="toc-number">7.</span> <span class="toc-text">7. k-均值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-随机森林"><span class="toc-number">8.</span> <span class="toc-text">8. 随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-降维算法"><span class="toc-number">9.</span> <span class="toc-text">9. 降维算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-梯度提升算法"><span class="toc-number">10.</span> <span class="toc-text">10.梯度提升算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-1-GBM"><span class="toc-number">10.1.</span> <span class="toc-text">10.1 GBM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-XGBoost"><span class="toc-number">10.2.</span> <span class="toc-text">10.2 XGBoost</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-3-LightGBM"><span class="toc-number">10.3.</span> <span class="toc-text">10.3 LightGBM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-4-Catboost"><span class="toc-number">10.4.</span> <span class="toc-text">10.4 Catboost</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Reference"><span class="toc-number">10.5.</span> <span class="toc-text">Reference:</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        机器学习常用算法
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Robby</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-06-06T09:48:52.000Z" itemprop="datePublished">2020-06-06</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/machine-learning/">machine learning</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/algorithm/">algorithm</a>, <a class="tag-link" href="/tags/machine-learning/">machine learning</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>[TOC]</p>
<ol>
<li>线性回归</li>
<li>逻辑回归</li>
<li>决策树</li>
<li>支持向量机</li>
<li>朴素贝叶斯</li>
<li>神经网络</li>
<li>K均值</li>
<li>随机森林</li>
<li>降维算法</li>
<li>梯度提升算法</li>
</ol>
<ul>
<li>GBM</li>
<li>XGBoost</li>
<li>LightGBM</li>
<li>catboost</li>
</ul>
<h3 id="1-线性回归"><a href="#1-线性回归" class="headerlink" title="1.线性回归"></a>1.线性回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 线性回归主要有两种类型：简单线性回归和多重线性回归。简单线性回归的特征在于一个独立变量。并且，多重线性回归（顾名思义）具有多个（大于1个）</span></span><br><span class="line"><span class="comment"># 独立变量的特征。找到最佳拟合线时，可以拟合多项式或曲线回归。这些被称为多项式或曲线回归。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the Linear Regression</span></span><br><span class="line"><span class="string">Created by- ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/linear_regression/train.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/linear_regression/test.csv'</span>)</span><br><span class="line"></span><br><span class="line">train_data.head()</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Item_Weight</th>
      <th>Item_Visibility</th>
      <th>Item_MRP</th>
      <th>Outlet_Establishment_Year</th>
      <th>Item_Outlet_Sales</th>
      <th>Item_Fat_Content_LF</th>
      <th>Item_Fat_Content_Low Fat</th>
      <th>Item_Fat_Content_Regular</th>
      <th>Item_Fat_Content_low fat</th>
      <th>Item_Fat_Content_reg</th>
      <th>...</th>
      <th>Outlet_Size_High</th>
      <th>Outlet_Size_Medium</th>
      <th>Outlet_Size_Small</th>
      <th>Outlet_Location_Type_Tier 1</th>
      <th>Outlet_Location_Type_Tier 2</th>
      <th>Outlet_Location_Type_Tier 3</th>
      <th>Outlet_Type_Grocery Store</th>
      <th>Outlet_Type_Supermarket Type1</th>
      <th>Outlet_Type_Supermarket Type2</th>
      <th>Outlet_Type_Supermarket Type3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18.100</td>
      <td>0.022526</td>
      <td>95.0094</td>
      <td>2007</td>
      <td>1713.7692</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6.615</td>
      <td>0.093575</td>
      <td>199.4426</td>
      <td>2002</td>
      <td>3361.6242</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>11.850</td>
      <td>0.050187</td>
      <td>164.1526</td>
      <td>2002</td>
      <td>3124.5994</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.500</td>
      <td>0.159969</td>
      <td>147.6102</td>
      <td>1999</td>
      <td>1603.9122</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>14.000</td>
      <td>0.029769</td>
      <td>145.4786</td>
      <td>1999</td>
      <td>1300.3074</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 36 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (341, 36)

Shape of testing data : (1364, 36)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
RangeIndex: 341 entries, 0 to 340
Data columns (total 36 columns):
 #   Column                           Non-Null Count  Dtype  
---  ------                           --------------  -----  
 0   Item_Weight                      341 non-null    float64
 1   Item_Visibility                  341 non-null    float64
 2   Item_MRP                         341 non-null    float64
 3   Outlet_Establishment_Year        341 non-null    int64  
 4   Item_Outlet_Sales                341 non-null    float64
 5   Item_Fat_Content_LF              341 non-null    int64  
 6   Item_Fat_Content_Low Fat         341 non-null    int64  
 7   Item_Fat_Content_Regular         341 non-null    int64  
 8   Item_Fat_Content_low fat         341 non-null    int64  
 9   Item_Fat_Content_reg             341 non-null    int64  
 10  Item_Type_Baking Goods           341 non-null    int64  
 11  Item_Type_Breads                 341 non-null    int64  
 12  Item_Type_Breakfast              341 non-null    int64  
 13  Item_Type_Canned                 341 non-null    int64  
 14  Item_Type_Dairy                  341 non-null    int64  
 15  Item_Type_Frozen Foods           341 non-null    int64  
 16  Item_Type_Fruits and Vegetables  341 non-null    int64  
 17  Item_Type_Hard Drinks            341 non-null    int64  
 18  Item_Type_Health and Hygiene     341 non-null    int64  
 19  Item_Type_Household              341 non-null    int64  
 20  Item_Type_Meat                   341 non-null    int64  
 21  Item_Type_Others                 341 non-null    int64  
 22  Item_Type_Seafood                341 non-null    int64  
 23  Item_Type_Snack Foods            341 non-null    int64  
 24  Item_Type_Soft Drinks            341 non-null    int64  
 25  Item_Type_Starchy Foods          341 non-null    int64  
 26  Outlet_Size_High                 341 non-null    int64  
 27  Outlet_Size_Medium               341 non-null    int64  
 28  Outlet_Size_Small                341 non-null    int64  
 29  Outlet_Location_Type_Tier 1      341 non-null    int64  
 30  Outlet_Location_Type_Tier 2      341 non-null    int64  
 31  Outlet_Location_Type_Tier 3      341 non-null    int64  
 32  Outlet_Type_Grocery Store        341 non-null    int64  
 33  Outlet_Type_Supermarket Type1    341 non-null    int64  
 34  Outlet_Type_Supermarket Type2    341 non-null    int64  
 35  Outlet_Type_Supermarket Type3    341 non-null    int64  
dtypes: float64(4), int64(32)
memory usage: 96.0 KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.columns</span><br></pre></td></tr></table></figure>

<pre><code>Index([&apos;Item_Weight&apos;, &apos;Item_Visibility&apos;, &apos;Item_MRP&apos;,
       &apos;Outlet_Establishment_Year&apos;, &apos;Item_Outlet_Sales&apos;, &apos;Item_Fat_Content_LF&apos;,
       &apos;Item_Fat_Content_Low Fat&apos;, &apos;Item_Fat_Content_Regular&apos;,
       &apos;Item_Fat_Content_low fat&apos;, &apos;Item_Fat_Content_reg&apos;,
       &apos;Item_Type_Baking Goods&apos;, &apos;Item_Type_Breads&apos;, &apos;Item_Type_Breakfast&apos;,
       &apos;Item_Type_Canned&apos;, &apos;Item_Type_Dairy&apos;, &apos;Item_Type_Frozen Foods&apos;,
       &apos;Item_Type_Fruits and Vegetables&apos;, &apos;Item_Type_Hard Drinks&apos;,
       &apos;Item_Type_Health and Hygiene&apos;, &apos;Item_Type_Household&apos;, &apos;Item_Type_Meat&apos;,
       &apos;Item_Type_Others&apos;, &apos;Item_Type_Seafood&apos;, &apos;Item_Type_Snack Foods&apos;,
       &apos;Item_Type_Soft Drinks&apos;, &apos;Item_Type_Starchy Foods&apos;, &apos;Outlet_Size_High&apos;,
       &apos;Outlet_Size_Medium&apos;, &apos;Outlet_Size_Small&apos;,
       &apos;Outlet_Location_Type_Tier 1&apos;, &apos;Outlet_Location_Type_Tier 2&apos;,
       &apos;Outlet_Location_Type_Tier 3&apos;, &apos;Outlet_Type_Grocery Store&apos;,
       &apos;Outlet_Type_Supermarket Type1&apos;, &apos;Outlet_Type_Supermarket Type2&apos;,
       &apos;Outlet_Type_Supermarket Type3&apos;],
      dtype=&apos;object&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Item_Outlet_Sales</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Linear Regression model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : fit_intercept and normalize</span></span><br><span class="line"><span class="string">Documentation of sklearn LinearRegression: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># coefficeints of the trained model</span></span><br><span class="line">print(<span class="string">'\nCoefficient of model :'</span>, model.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># intercept of the model</span></span><br><span class="line">print(<span class="string">'\nIntercept of model'</span>,model.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>Coefficient of model : [-9.43246817e+00 -1.36334814e+03  1.47120996e+01  5.25716701e+00
 -3.08160713e+02  5.40196700e+01  1.46460862e+02 -1.86881844e+02
  2.94562026e+02 -1.20978659e+02  1.91147902e+02  2.88841813e+02
  1.20939032e+02  4.93700723e-01  1.65245097e+02  7.99978995e+01
 -3.43206623e+01  2.16267915e+02  2.03907820e+02 -2.13523836e+02
 -1.57753096e+02 -8.76784016e+02 -6.45155297e+01  3.73702500e+02
 -1.72667882e+02  6.14237025e+01  3.82735364e+02  5.84575790e+01
 -1.54896394e+02  1.80902953e+02 -2.60065591e+01 -1.21501720e+03
  1.94800651e+02 -2.75523130e+02  1.29573968e+03]

Intercept of model -10702.945886779742</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nItem_Outlet_Sales on training data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Root Mean Squared Error on training dataset</span></span><br><span class="line">rmse_train = mean_squared_error(train_y,predict_train)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on train dataset : '</span>, rmse_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the testing dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nItem_Outlet_Sales on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Root Mean Squared Error on testing dataset</span></span><br><span class="line">rmse_test = mean_squared_error(test_y,predict_test)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on test dataset : '</span>, rmse_test)</span><br></pre></td></tr></table></figure>

<pre><code>Item_Outlet_Sales on training data [ 1554.25836991  2996.36806365  2658.89749641  2281.45355388
  2343.38090589  3774.162307    2496.2270017   1085.25819535
  3627.45476827  1219.5359806   2088.85506246   921.30255577
   178.4433023   1140.60835401  2559.43295864   836.96268557
  2420.67597278  1751.72767689  1796.99389781  3824.14515917
   564.94106486  1233.88446997  2145.20657514  2969.43374393
   896.78051443  1525.82567574   483.33148216  2209.02101609
  2862.21605657  1568.98791229  1993.95285368  3038.64269043
  2703.45493561   326.18505855  3759.20381589  2306.08329193
  1892.85225139  2785.72042443  2513.33413645  3632.17397732
  2093.34330991   674.09102307  -893.27190909  1538.86951004
   564.17259803  1744.8277889   3156.03404374  2375.96966998
  1292.64807587  -169.23424653  1965.93949868  3585.86483674
  1702.48929434  2431.2557754   1655.73491164   766.53800971
  2730.52591894  1611.04553547  2168.75380434  2887.95349015
   146.87696798   108.76638605  3861.35358703  2927.14377573
  4211.77558071   730.10650962  1389.87795567   640.80185107
   924.77266537  1886.27052057  1316.46061274  3323.30073316
  1544.02494831   523.7929799   1512.20706222   681.72868074
  1192.66278316   294.14170175   951.20060881   250.41977271
  1305.15483221   976.36051998  2475.28505863  1830.87630739
  2373.29545086  3422.89379698   795.90827829  3741.58366161
  1205.67866667  1094.53554945  2576.46490134  1651.36424992
  1531.49910054  3795.08124028   816.715901    4531.97485658
  3847.07846017  2170.28065118  2877.08651106  1663.78665866
  3386.6447335   3179.00642007  2946.77550672   697.47155564
  2577.91500955  1498.92222674  2606.07417457  3657.10329414
   660.32800572  1904.27834427   822.7966164   2159.89516106
  1890.84520447  3481.90713152  2699.91056538   882.22545205
  1924.60766018  1691.07081446  3610.33773957  1118.13625807
  1284.44837907  1791.52373956  2005.17802984  2053.17381652
  2158.48309389   -66.02643436  2099.11847189  3480.09246017
  4123.93605389  2356.28698978  1959.88733885  1112.28484081
  -696.24391444   515.53089684  4981.12584838 -1054.43091021
  1542.42957464  2817.02145483  1597.18773775  1456.4756461
  1252.959179    3533.20148823  1210.47408385  1408.41803559
  2120.00916962  3390.64286684  2907.21836109  1086.14914755
  2145.67152466  5195.40237662  -732.73146899  3074.08209299
  1854.68363855  2021.820769    3972.87706184   898.39005193
  1698.6309594   1906.02870309  2301.00594487  1979.47328624
  1434.77213776   913.60212362  3592.26144548  1676.83035628
  2822.97657494  3320.81209022  1084.79320515  2323.89089836
  1472.67265555  1679.72169447  -786.59903333   663.64430252
  1995.89552507   723.64710047  1417.26920873  2249.93150841
  1496.07261262  2850.33998037   559.05280386   374.93061212
   717.60237725  2322.80393288  1471.04478435  2269.46794949
  1612.21043491  2813.28870597  2418.37590778  1706.61635477
  3486.75610609  2028.67359664  3840.79448996  1247.39251862
  2486.05518257  1147.40177928   516.29691658  2263.12640926
  3763.63502165  2788.73077704  1706.07209217  1756.83687179
  -353.40220188  2048.87709358  2397.06239698  2622.84988602
  3922.79094831  2244.67738234  3709.47656206  4102.26622895
  2224.82858385  1811.64026696  3055.50324654  2021.92948689
  2100.60040733   608.92668987  1609.59661315  2352.63307891
  1554.59532561  1816.77896782  3120.88240171   763.85932933
  2478.84012799  2960.85929052  2972.4776307   2385.70564565
   177.77097079  3137.60935396  3450.4983667   3201.94249834
  3284.62636436  2257.54696268   928.1498812   2250.51914388
  4227.07468474  2638.22588696  2261.35284468  -915.27686919
   126.79739524  2512.06820187  2450.98868529  3090.09892589
  4396.03716761  3282.31606229  2735.4340587   2894.34434634
   910.42784972  3600.0714645   1874.12378574  3612.23043314
  1954.50081489  2205.59253997  3638.34772242  1619.1911086
   192.55747933  1412.66878896  1427.74902805  1396.38815722
  1534.45836625   972.274295    2655.19203248  2680.81316786
   253.42571843   390.73227035  1703.00417502  -225.70347094
  2000.96558298  4140.45921526  1776.49697229  2827.79201459
  2315.83749133  3748.32807374  -851.40331625  1315.62507584
  -625.77327446  1897.05762315  2962.73214713  2209.45981823
  1538.48645474  3077.71100882  -579.89940554  2789.08359364
  2300.48923513  2511.49038398  1714.53604556  2574.37779058
  4079.40060265  2929.68160405  2167.67814658   886.61607699
  1680.86808728  4050.07648213  2755.02682707  3259.19686503
  3961.06602332  1688.21173627  3908.31243928   415.71086491
  2171.32562312  2800.82432172  2493.46724086  2255.1842403
  3452.40694946  3555.20970436  3713.51140259  3913.54851144
  3768.63451761  3913.49822063  3410.87882523  2739.86035756
   785.67914794   569.19926236  1749.22839886  4913.22096122
  2045.62451993  1711.84713747  3066.64447943   413.70596869
  4498.4542021   2695.14466309  3399.55871278   598.09730467
  2482.37542211  2786.78478841   623.55368861  2723.07093916
  1798.05920089  2492.44746589  2881.88040633  3728.12119052
  1468.29026402  1081.21846511  2999.34288004  5093.88623252
  1355.37380799   546.58951046  1364.06076559  3715.95983047
  3264.95983372  3143.73476079  3203.07924204  1450.99885052
   549.88608479]

RMSE on train dataset :  939.5696617002172

Item_Outlet_Sales on test data [ 799.42439897 1335.25100551 2994.21059824 ...  940.31776908 2621.52833639
 2530.18142102]

RMSE on test dataset :  1195.4204805979339</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-逻辑回归"><a href="#2-逻辑回归" class="headerlink" title="2. 逻辑回归"></a>2. 逻辑回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Logistic Regression</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(train_data.head())</span><br></pre></td></tr></table></figure>

<pre><code>   Survived        Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \
0         0  28.500000   7.2292         0         0         1           0   
1         1  27.000000  10.5000         0         1         0           1   
2         1  29.699118  16.1000         0         0         1           1   
3         0  29.699118   0.0000         1         0         0           0   
4         0  17.000000   8.6625         0         0         1           0   

   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \
0         1        1        0  ...        1        0        0        0   
1         0        1        0  ...        1        0        0        0   
2         0        0        1  ...        1        0        0        0   
3         1        1        0  ...        1        0        0        0   
4         1        1        0  ...        1        0        0        0   

   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  
0        0        0        0           1           0           0  
1        0        0        0           0           0           1  
2        0        0        0           0           0           1  
3        0        0        0           0           0           1  
4        0        0        0           0           0           1  

[5 rows x 25 columns]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (712, 25)
Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Logistic Regression model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : fit_intercept and penalty</span></span><br><span class="line"><span class="string">Documentation of sklearn LogisticRegression: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># coefficeints of the trained model</span></span><br><span class="line">print(<span class="string">'Coefficient of model :'</span>, model.coef_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># intercept of the model</span></span><br><span class="line">print(<span class="string">'Intercept of model'</span>,model.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>Coefficient of model : [[-0.03112934  0.00155783  0.93301967  0.08453536 -1.02562082  1.2453337
  -1.25339949  1.05045964  0.97900276  0.61562231 -1.14084691 -0.7809188
  -0.28356218 -0.44782261  0.1617448   0.63397297 -0.0470682   0.20461703
  -0.4576669  -0.3367795  -0.16688599  0.07950782  0.28572137 -0.37329498]]
Intercept of model [0.07225876]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1
 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0
 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1
 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0
 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1
 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1
 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0
 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1
 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1
 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0
 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1
 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1
 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0
 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1
 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0
 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0
 1 0 1 1 1 0 1 0 0]
accuracy_score on train dataset :  0.8047752808988764
Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1
 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1]
accuracy_score on test dataset :  0.8324022346368715</code></pre><h5 id="改进模型"><a href="#改进模型" class="headerlink" title="改进模型"></a>改进模型</h5><ul>
<li>including interaction terms</li>
<li>removing features</li>
<li>regularization techniques</li>
<li>using a non-linear model</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3-决策树"><a href="#3-决策树" class="headerlink" title="3. 决策树"></a>3. 决策树</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Decision Tree</span></span><br><span class="line"><span class="string">Created by - Analytics Vidhya</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (712, 25)
Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Decision Tree model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : max_depth and max_features</span></span><br><span class="line"><span class="string">Documentation of sklearn DecisionTreeClassifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># depth of the decision tree</span></span><br><span class="line">print(<span class="string">'Depth of the Decision Tree :'</span>, model.get_depth())</span><br></pre></td></tr></table></figure>

<pre><code>Depth of the Decision Tree : 19</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0
 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0
 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1
 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0
 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0
 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1
 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1
 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0
 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0
 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1
 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0
 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1
 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0
 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0
 1 0 1 1 1 0 0 1 0]
accuracy_score on train dataset :  0.9859550561797753
Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1
 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0
 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 0 0
 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0
 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0]
accuracy_score on test dataset :  0.7486033519553073</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="4-支持向量机"><a href="#4-支持向量机" class="headerlink" title="4. 支持向量机"></a>4. 支持向量机</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Support Vector Machines</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (712, 25)
Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Support Vector Classifier model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : kernal and degree</span></span><br><span class="line"><span class="string">Documentation of sklearn Support Vector Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0
 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0
 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0
 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1
 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0
 1 0 0 0 1 0 1 0 0]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>accuracy_score on train dataset :  0.651685393258427
Target on test data [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0
 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
accuracy_score on test dataset :  0.7262569832402235</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="5-朴素贝叶斯"><a href="#5-朴素贝叶斯" class="headerlink" title="5. 朴素贝叶斯"></a>5. 朴素贝叶斯</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Naive Bayes</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (712, 25)
Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the Naive Bayes model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : var_smoothing</span></span><br><span class="line"><span class="string">Documentation of sklearn GaussianNB: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = GaussianNB()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'Target on train data'</span>,predict_train)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1
 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1
 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1
 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1
 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>accuracy_score on train dataset :  0.44803370786516855
Target on test data [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1
 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
accuracy_score on test dataset :  0.35195530726256985</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="6-kNN-k最近邻"><a href="#6-kNN-k最近邻" class="headerlink" title="6. kNN(k最近邻)"></a>6. kNN(k最近邻)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the K-Nearest Neighbors</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (712, 25)
Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the K-Nearest Neighbor model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_neighbors, leaf_size</span></span><br><span class="line"><span class="string">Documentation of sklearn K-Neighbors Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line">model = KNeighborsClassifier()  </span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Neighbors used to predict the target</span></span><br><span class="line">print(<span class="string">'\nThe number of neighbors used to predict the target : '</span>,model.n_neighbors)</span><br></pre></td></tr></table></figure>

<pre><code>The number of neighbors used to predict the target :  5</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'accuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'Target on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'accuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0
 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0
 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0
 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0
 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1
 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0
 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0
 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1
 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0
 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1
 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0
 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0
 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1
 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0
 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0
 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1
 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0
 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0
 1 0 1 1 1 0 0 1 0]
accuracy_score on train dataset :  0.8047752808988764
Target on test data [0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0
 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 1
 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0]
accuracy_score on test dataset :  0.7150837988826816</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="7-k-均值"><a href="#7-k-均值" class="headerlink" title="7. k-均值"></a>7. k-均值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the K-Means</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/k_means/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/k_means/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (100, 5)
Shape of testing data : (100, 5)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to divide the training data into differernt clusters</span></span><br><span class="line"><span class="comment"># and predict in which cluster a particular data point belongs.  </span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the K-Means model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_clusters and max_iter</span></span><br><span class="line"><span class="string">Documentation of sklearn KMeans: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</span></span><br><span class="line"><span class="string"> '''</span></span><br><span class="line"></span><br><span class="line">model = KMeans()  </span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Clusters</span></span><br><span class="line">print(<span class="string">'\nDefault number of Clusters : '</span>,model.n_clusters)</span><br></pre></td></tr></table></figure>

<pre><code>Default number of Clusters :  8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the clusters on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_data)</span><br><span class="line">print(<span class="string">'\nCLusters on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_data)</span><br><span class="line">print(<span class="string">'Clusters on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, we will train a model with n_cluster = 3</span></span><br><span class="line">model_n3 = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model_n3.fit(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of Clusters</span></span><br><span class="line">print(<span class="string">'\nNumber of Clusters : '</span>,model_n3.n_clusters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the clusters on the train dataset</span></span><br><span class="line">predict_train_3 = model_n3.predict(train_data)</span><br><span class="line">print(<span class="string">'\nCLusters on train data'</span>,predict_train_3) </span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test_3 = model_n3.predict(test_data)</span><br><span class="line">print(<span class="string">'Clusters on test data'</span>,predict_test_3)</span><br></pre></td></tr></table></figure>

<pre><code>CLusters on train data [5 3 4 3 5 2 2 3 3 7 1 1 6 4 3 1 4 0 2 5 0 6 6 4 0 4 1 1 4 6 0 6 6 4 4 1 7
 1 7 6 4 7 1 1 4 6 6 4 3 1 6 4 2 1 4 1 2 7 5 7 6 5 2 4 6 4 0 6 6 1 2 1 5 2
 3 3 5 6 2 6 2 6 1 2 7 2 4 6 7 6 0 3 1 4 1 2 6 5 1 5]
Clusters on test data [6 5 7 4 2 5 4 6 2 0 6 0 2 2 2 6 6 2 2 3 4 4 2 2 6 2 4 5 2 4 1 5 6 2 5 4 1
 3 6 4 4 5 7 4 2 6 2 3 6 6 0 5 6 1 5 6 1 6 6 7 6 6 2 1 3 2 1 2 6 6 2 7 4 1
 2 4 6 4 6 5 6 2 0 4 7 5 6 2 5 4 5 0 6 2 4 5 5 5 1 4]

Number of Clusters :  3

CLusters on train data [1 0 2 0 1 2 1 0 0 1 0 0 1 2 0 0 2 1 1 1 1 1 1 2 1 2 0 0 2 1 1 1 1 2 2 0 1
 0 1 1 2 1 0 0 2 1 1 2 0 0 1 2 1 0 2 0 1 1 1 1 1 1 1 2 1 2 1 1 1 0 2 0 1 1
 0 0 0 1 0 1 1 1 0 1 1 1 2 1 1 1 1 0 0 2 0 1 1 1 0 1]
Clusters on test data [1 1 1 2 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 0 2 2 1 1 1 1 2 1 1 2 0 1 1 1 1 2 0
 0 1 2 2 1 1 2 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 2 0
 1 2 1 2 1 0 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 0 2]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="8-随机森林"><a href="#8-随机森林" class="headerlink" title="8. 随机森林"></a>8. 随机森林</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for the Random Forest</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># view the top 3 rows of the dataset</span></span><br><span class="line">print(train_data.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>   Survived        Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \
0         0  28.500000   7.2292         0         0         1           0   
1         1  27.000000  10.5000         0         1         0           1   
2         1  29.699118  16.1000         0         0         1           1   

   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \
0         1        1        0  ...        1        0        0        0   
1         0        1        0  ...        1        0        0        0   
2         0        0        1  ...        1        0        0        0   

   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  
0        0        0        0           1           0           0  
1        0        0        0           0           0           1  
2        0        0        0           0           0           1  

[3 rows x 25 columns]

Shape of training data : (712, 25)

Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Create the object of the Random Forest model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : n_estimators and max_depth</span></span><br><span class="line"><span class="string">Documentation of sklearn RandomForestClassifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = RandomForestClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># number of trees used</span></span><br><span class="line">print(<span class="string">'Number of Trees used : '</span>, model.n_estimators)</span><br></pre></td></tr></table></figure>

<pre><code>Number of Trees used :  100</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0
 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0
 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1
 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0
 0 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0
 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1
 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0
 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1
 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0
 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0
 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1
 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0
 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1
 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 0
 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0
 1 0 1 1 1 0 0 1 0]

accuracy_score on train dataset :  0.9859550561797753

Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 1 0
 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0
 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 1
 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0
 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]

accuracy_score on test dataset :  0.8156424581005587</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="9-降维算法"><a href="#9-降维算法" class="headerlink" title="9. 降维算法"></a>9. 降维算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Principal Component Analysis (PCA)</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/dimensionality_reduction_algorithms/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/dimensionality_reduction_algorithms/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># view the top 3 rows of the dataset</span></span><br><span class="line">print(train_data.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'\nShape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'\nShape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>   Item_Weight  Item_Visibility  Item_MRP  Outlet_Establishment_Year  \
0     6.800000         0.037490   48.6034                       2004   
1    15.600000         0.172597  114.8518                       1997   
2    12.911575         0.054721  107.8254                       1985   

   Item_Outlet_Sales  Item_Fat_Content_LF  Item_Fat_Content_Low Fat  \
0           291.6204                    0                         1   
1          2163.1842                    0                         1   
2          2387.5588                    0                         1   

   Item_Fat_Content_Regular  Item_Fat_Content_low fat  Item_Fat_Content_reg  \
0                         0                         0                     0   
1                         0                         0                     0   
2                         0                         0                     0   

   ...  Outlet_Size_High  Outlet_Size_Medium  Outlet_Size_Small  \
0  ...                 0                   0                  1   
1  ...                 0                   0                  1   
2  ...                 0                   1                  0   

   Outlet_Location_Type_Tier 1  Outlet_Location_Type_Tier 2  \
0                            0                            1   
1                            1                            0   
2                            0                            0   

   Outlet_Location_Type_Tier 3  Outlet_Type_Grocery Store  \
0                            0                          0   
1                            0                          0   
2                            1                          0   

   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \
0                              1                              0   
1                              1                              0   
2                              0                              0   

   Outlet_Type_Supermarket Type3  
0                              0  
1                              0  
2                              1  

[3 rows x 36 columns]

Shape of training data : (1364, 36)

Shape of testing data : (341, 36)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line"><span class="comment"># target variable - Item_Outlet_Sales</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Item_Outlet_Sales'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Item_Outlet_Sales'</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\nTraining model with &#123;&#125; dimensions.'</span>.format(train_x.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>Training model with 35 dimensions.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create object of model</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">rmse_train = mean_squared_error(train_y,predict_train)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on train dataset : '</span>, rmse_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">rmse_test = mean_squared_error(test_y,predict_test)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on test dataset : '</span>, rmse_test)</span><br></pre></td></tr></table></figure>

<pre><code>RMSE on train dataset :  1135.8159344155242

RMSE on test dataset :  1009.2517232209691</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create the object of the PCA (Principal Component Analysis) model</span></span><br><span class="line"><span class="comment"># reduce the dimensions of the data to 12</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : svd_solver, iterated_power</span></span><br><span class="line"><span class="string">Documentation of sklearn PCA:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model_pca = PCA(n_components=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">new_train = model_pca.fit_transform(train_x)</span><br><span class="line">new_test  = model_pca.fit_transform(test_x)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\nTraining model with &#123;&#125; dimensions.'</span>.format(new_train.shape[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>Training model with 12 dimensions.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create object of model</span></span><br><span class="line">model_new = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model_new.fit(new_train,train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the new train dataset</span></span><br><span class="line">predict_train_pca = model_new.predict(new_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">rmse_train_pca = mean_squared_error(train_y,predict_train_pca)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on new train dataset : '</span>, rmse_train_pca)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the new test dataset</span></span><br><span class="line">predict_test_pca = model_new.predict(new_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">rmse_test_pca = mean_squared_error(test_y,predict_test_pca)**(<span class="number">0.5</span>)</span><br><span class="line">print(<span class="string">'\nRMSE on new test dataset : '</span>, rmse_test_pca)</span><br></pre></td></tr></table></figure>

<pre><code>RMSE on new train dataset :  1159.9753332539403

RMSE on new test dataset :  1014.4112713739024</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="10-梯度提升算法"><a href="#10-梯度提升算法" class="headerlink" title="10.梯度提升算法"></a>10.梯度提升算法</h3><h4 id="10-1-GBM"><a href="#10-1-GBM" class="headerlink" title="10.1 GBM"></a>10.1 GBM</h4><p>当我们处理大量数据以进行具有高预测能力的预测时，GBM是一种增强算法。Boosting实际上是一种学习算法的集合，该算法结合了多个基本估计量<br>的预测，从而提高了单个估计量的鲁棒性。它将多个弱或平均预测变量组合为一个构建强的预测变量。这些增强算法在像Kaggle，AV Hackathon，<br>CrowdAnalytix之类的数据科学竞赛中始终能很好地发挥作用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for Gradient Boosting</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (712, 25)
Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the GradientBoosting Classifier model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : learning_rate, n_estimators</span></span><br><span class="line"><span class="string">Documentation of sklearn GradientBoosting Classifier: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = GradientBoostingClassifier(n_estimators=<span class="number">100</span>,max_depth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br></pre></td></tr></table></figure>

<pre><code>GradientBoostingClassifier(ccp_alpha=0.0, criterion=&apos;friedman_mse&apos;, init=None,
                           learning_rate=0.1, loss=&apos;deviance&apos;, max_depth=5,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=100,
                           n_iter_no_change=None, presort=&apos;deprecated&apos;,
                           random_state=None, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0
 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0
 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0
 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1
 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0
 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0
 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1
 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1
 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0
 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0
 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1
 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0
 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1
 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0
 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0
 1 0 1 1 1 0 0 1 0]

accuracy_score on train dataset :  0.9592696629213483

Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1
 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0
 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0]

accuracy_score on test dataset :  0.8212290502793296</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="10-2-XGBoost"><a href="#10-2-XGBoost" class="headerlink" title="10.2 XGBoost"></a>10.2 XGBoost</h4><ul>
<li><p>在某些Kaggle比赛中，另一种经典的梯度提升算法是决定胜负的决定性选择。</p>
</li>
<li><p>XGBoost具有极高的预测能力，这使其成为事件准确性的最佳选择，因为它同时具有线性模型和树学习算法，这使得该算法比现有的梯度增强技术快近10倍。</p>
</li>
<li><p>支持包括各种目标功能，包括回归，分类和排名。</p>
</li>
<li><p>关于XGBoost的最有趣的事情之一是它也被称为正则化增强技术。这有助于减少过拟合模型，并且对Scala，Java，R，Python，<br>Julia和C ++等多种语言提供了广泛的支持。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">The following code is for XGBoost</span></span><br><span class="line"><span class="string">Created by - ANALYTICS VIDHYA</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># importing required libraries</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read the train and test dataset</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/logistic_regression/train-data.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/logistic_regression/test-data.csv'</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shape of the dataset</span></span><br><span class="line">print(<span class="string">'Shape of training data :'</span>,train_data.shape)</span><br><span class="line">print(<span class="string">'Shape of testing data :'</span>,test_data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Shape of training data : (712, 25)
Shape of testing data : (179, 25)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now, we need to predict the missing target variable in the test data</span></span><br><span class="line"><span class="comment"># target variable - Survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on training data</span></span><br><span class="line">train_x = train_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">train_y = train_data[<span class="string">'Survived'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># seperate the independent and target variable on testing data</span></span><br><span class="line">test_x = test_data.drop(columns=[<span class="string">'Survived'</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_y = test_data[<span class="string">'Survived'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Create the object of the XGBoost model</span></span><br><span class="line"><span class="string">You can also add other parameters and test your code here</span></span><br><span class="line"><span class="string">Some parameters are : max_depth and n_estimators</span></span><br><span class="line"><span class="string">Documentation of xgboost:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">https://xgboost.readthedocs.io/en/latest/</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">model = XGBClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit the model with the training data</span></span><br><span class="line">model.fit(train_x,train_y)</span><br></pre></td></tr></table></figure>

<pre><code>XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
              importance_type=&apos;gain&apos;, interaction_constraints=None,
              learning_rate=0.300000012, max_delta_step=0, max_depth=6,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=0, num_parallel_tree=1,
              objective=&apos;binary:logistic&apos;, random_state=0, reg_alpha=0,
              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,
              validate_parameters=False, verbosity=None)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict the target on the train dataset</span></span><br><span class="line">predict_train = model.predict(train_x)</span><br><span class="line">print(<span class="string">'\nTarget on train data'</span>,predict_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuray Score on train dataset</span></span><br><span class="line">accuracy_train = accuracy_score(train_y,predict_train)</span><br><span class="line">print(<span class="string">'\naccuracy_score on train dataset : '</span>, accuracy_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict the target on the test dataset</span></span><br><span class="line">predict_test = model.predict(test_x)</span><br><span class="line">print(<span class="string">'\nTarget on test data'</span>,predict_test) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy Score on test dataset</span></span><br><span class="line">accuracy_test = accuracy_score(test_y,predict_test)</span><br><span class="line">print(<span class="string">'\naccuracy_score on test dataset : '</span>, accuracy_test)</span><br></pre></td></tr></table></figure>

<pre><code>Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0
 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0
 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0
 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1
 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0
 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0
 0 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1
 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1
 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 0
 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0
 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1
 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1
 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0
 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1
 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 0
 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0
 1 0 1 1 1 0 0 1 0]

accuracy_score on train dataset :  0.9691011235955056

Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1
 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0
 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0]

accuracy_score on test dataset :  0.8491620111731844</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="10-3-LightGBM"><a href="#10-3-LightGBM" class="headerlink" title="10.3 LightGBM"></a>10.3 LightGBM</h4><p>LightGBM是使用基于树的学习算法的梯度增强框架。它被设计为分布式且高效的，具有以下优点：</p>
<ul>
<li><p>更快的训练速度和更高的效率</p>
</li>
<li><p>降低内存使用量</p>
</li>
<li><p>精度更高</p>
</li>
<li><p>支持并行和GPU学习</p>
</li>
<li><p>能够处理大规模数据</p>
</li>
<li><p>该框架是一种基于决策树算法的快速，高性能的梯度提升算法，用于排名，分类和许多其他机器学习任务。它是在Microsoft的分布式机器学习工具包项目下开发的。</p>
</li>
<li><p>由于LightGBM基于决策树算法，因此它以最佳拟合方式对树进行明智的拆分，而其他增强算法则对树的深度或层次进行明智的拆分，而不是对叶子进行拆分。因此，当在Light GBM中的同一叶上生长时，与逐级算法相比，逐叶算法可以减少更多的损失，因此可以得到更好的精度，而现有的任何增强算法都很少达到这种精度。</p>
</li>
<li><p>而且，它出奇地快，因此是“ Light”一词。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.random.rand(<span class="number">500</span>, <span class="number">10</span>) <span class="comment"># 500 entities, each contains 10 features</span></span><br><span class="line">label = np.random.randint(<span class="number">2</span>, size=<span class="number">500</span>) <span class="comment"># binary target</span></span><br><span class="line"></span><br><span class="line">print(data)</span><br><span class="line">print(label)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.85407276 0.76264687 0.76309089 ... 0.24686371 0.81810466 0.54510778]
 [0.18917982 0.84323576 0.67375987 ... 0.96928095 0.12899887 0.71734016]
 [0.2495302  0.2402824  0.34255779 ... 0.25282833 0.62956857 0.91903815]
 ...
 [0.81342255 0.12151744 0.98450246 ... 0.9917896  0.2163299  0.01477092]
 [0.79621253 0.0664173  0.39355076 ... 0.3951299  0.04004062 0.94483777]
 [0.81403619 0.28215426 0.0604652  ... 0.78573717 0.3345766  0.07464122]]
[1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1
 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1
 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1
 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1
 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 0
 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1
 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1
 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0
 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0
 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1
 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1
 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0
 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1
 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line">train_data = lgb.Dataset(data, label=label)</span><br><span class="line">test_data = train_data.create_valid(<span class="string">'test.svm'</span>)</span><br><span class="line"></span><br><span class="line">param = &#123;<span class="string">'num_leaves'</span>:<span class="number">31</span>, <span class="string">'num_trees'</span>:<span class="number">100</span>, <span class="string">'objective'</span>:<span class="string">'binary'</span>&#125;</span><br><span class="line">param[<span class="string">'metric'</span>] = <span class="string">'auc'</span></span><br><span class="line"></span><br><span class="line">num_round = <span class="number">10</span></span><br><span class="line">bst = lgb.train(param, train_data, num_round)</span><br><span class="line"></span><br><span class="line">bst.save_model(<span class="string">'model.txt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7 entities, each contains 10 features</span></span><br><span class="line">data = np.random.rand(<span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">ypred = bst.predict(data)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="10-4-Catboost"><a href="#10-4-Catboost" class="headerlink" title="10.4 Catboost"></a>10.4 Catboost</h4><ul>
<li><p>CatBoost是Yandex最近提供的开源机器学习算法。它可以轻松地与深度学习框架（如Google的TensorFlow和Apple的Core ML）集成。</p>
</li>
<li><p>关于CatBoost的最好之处在于，它不需要像其他ML模型一样进行大量的数据培训，并且可以处理多种数据格式。不会破坏它的坚固性。</p>
</li>
<li><p>在继续实施之前，请确保您能很好地处理丢失的数据。</p>
</li>
<li><p>Catboost可以自动处理分类变量，而不会显示类型转换错误，这可以帮助您专注于更好地调整模型，而不是解决琐碎的错误。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressor</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Read training and testing files</span></span><br><span class="line">train = pd.read_csv(<span class="string">"./input/linear_regression/train.csv"</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">"./input/linear_regression/test.csv"</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Imputing missing values for both train and test</span></span><br><span class="line">train.fillna(<span class="number">-999</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">test.fillna(<span class="number">-999</span>,inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Creating a training set for modeling and validation set to check model performance</span></span><br><span class="line">X = train.drop([<span class="string">'Item_Outlet_Sales'</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = train.Item_Outlet_Sales</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=<span class="number">0.7</span>, random_state=<span class="number">1234</span>)</span><br><span class="line">categorical_features_indices = np.where(X.dtypes != np.float)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># [0]数组转换为列表</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(categorical_features_indices)</span><br></pre></td></tr></table></figure>

<pre><code>[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
 27 28 29 30 31 32 33 34]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
RangeIndex: 341 entries, 0 to 340
Data columns (total 35 columns):
 #   Column                           Non-Null Count  Dtype  
---  ------                           --------------  -----  
 0   Item_Weight                      341 non-null    float64
 1   Item_Visibility                  341 non-null    float64
 2   Item_MRP                         341 non-null    float64
 3   Outlet_Establishment_Year        341 non-null    int64  
 4   Item_Fat_Content_LF              341 non-null    int64  
 5   Item_Fat_Content_Low Fat         341 non-null    int64  
 6   Item_Fat_Content_Regular         341 non-null    int64  
 7   Item_Fat_Content_low fat         341 non-null    int64  
 8   Item_Fat_Content_reg             341 non-null    int64  
 9   Item_Type_Baking Goods           341 non-null    int64  
 10  Item_Type_Breads                 341 non-null    int64  
 11  Item_Type_Breakfast              341 non-null    int64  
 12  Item_Type_Canned                 341 non-null    int64  
 13  Item_Type_Dairy                  341 non-null    int64  
 14  Item_Type_Frozen Foods           341 non-null    int64  
 15  Item_Type_Fruits and Vegetables  341 non-null    int64  
 16  Item_Type_Hard Drinks            341 non-null    int64  
 17  Item_Type_Health and Hygiene     341 non-null    int64  
 18  Item_Type_Household              341 non-null    int64  
 19  Item_Type_Meat                   341 non-null    int64  
 20  Item_Type_Others                 341 non-null    int64  
 21  Item_Type_Seafood                341 non-null    int64  
 22  Item_Type_Snack Foods            341 non-null    int64  
 23  Item_Type_Soft Drinks            341 non-null    int64  
 24  Item_Type_Starchy Foods          341 non-null    int64  
 25  Outlet_Size_High                 341 non-null    int64  
 26  Outlet_Size_Medium               341 non-null    int64  
 27  Outlet_Size_Small                341 non-null    int64  
 28  Outlet_Location_Type_Tier 1      341 non-null    int64  
 29  Outlet_Location_Type_Tier 2      341 non-null    int64  
 30  Outlet_Location_Type_Tier 3      341 non-null    int64  
 31  Outlet_Type_Grocery Store        341 non-null    int64  
 32  Outlet_Type_Supermarket Type1    341 non-null    int64  
 33  Outlet_Type_Supermarket Type2    341 non-null    int64  
 34  Outlet_Type_Supermarket Type3    341 non-null    int64  
dtypes: float64(3), int64(32)
memory usage: 93.4 KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#importing library and building model</span></span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> CatBoostRegressor</span><br><span class="line">model=CatBoostRegressor(iterations=<span class="number">50</span>, depth=<span class="number">3</span>, learning_rate=<span class="number">0.1</span>, loss_function=<span class="string">'RMSE'</span>)</span><br><span class="line"></span><br><span class="line">model.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_validation, y_validation),plot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">submission = pd.<span class="symbol">DataFrame</span>()</span><br><span class="line"></span><br><span class="line">submission[<span class="string">'Item_Identifier'</span>] = test[<span class="string">'Item_Identifier'</span>]</span><br><span class="line">submission[<span class="string">'Outlet_Identifier'</span>] = test[<span class="string">'Outlet_Identifier'</span>]</span><br><span class="line">submission[<span class="string">'Item_Outlet_Sales'</span>] = model.predict(test)</span><br></pre></td></tr></table></figure>

<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h4><ol>
<li><a href="https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/?#" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/?#</a></li>
<li>Learn more about Catboost from this article: <a href="https://www.analyticsvidhya.com/blog/2017/08/catboost-automated-categorical-data/" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2017/08/catboost-automated-categorical-data/</a></li>
<li>Refer to the article to know more about LightGBM: <a href="https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/</a></li>
<li>To learn more about XGBoost and parameter tuning, visit <a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/</a>.</li>
<li>GradientBoostingClassifier and Random Forest are two different boosting tree classifier and often people ask about the <a href="http://discuss.analyticsvidhya.com/t/what-is-the-fundamental-difference-between-randomforest-and-gradient-boosting-algorithms/2341" target="_blank" rel="noopener">difference between these two algorithms</a>.</li>
<li>More: <a href="https://www.analyticsvidhya.com/blog/2015/05/boosting-algorithms-simplified/" target="_blank" rel="noopener">Know about Boosting algorithms in detail</a></li>
<li>To know more about this algorithms, you can read “<a href="https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/" target="_blank" rel="noopener">Beginners Guide To Learn Dimension Reduction Techniques</a>“.</li>
<li><a href="https://www.analyticsvidhya.com/blog/2014/06/introduction-random-forest-simplified/" target="_blank" rel="noopener">Introduction to Random forest – Simplified</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2014/06/comparing-cart-random-forest-1/" target="_blank" rel="noopener">Comparing a CART model to Random Forest (Part 1)</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2014/06/comparing-random-forest-simple-cart-model/" target="_blank" rel="noopener">Comparing a Random Forest to a CART model (Part 2)</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/" target="_blank" rel="noopener">Tuning the parameters of your Random Forest model</a></li>
<li>More: [Introduction to k-nearest neighbors : Simplified](<a href="http://introduction" target="_blank" rel="noopener">http://introduction</a> to k-nearest neighbors : Simplified/).</li>
<li>More: <a href="https://www.analyticsvidhya.com/blog/2014/10/support-vector-machine-simplified/" target="_blank" rel="noopener">Simplified Version of Support Vector Machine</a></li>
<li><em>More</em>: <a href="https://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/" target="_blank" rel="noopener">Simplified Version of Decision Tree Algorithms</a></li>
<li>For more details, you can read: <a href="https://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/" target="_blank" rel="noopener">Decision Tree Simplified</a>.</li>
</ol>

  </div>
</article>



    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
    <div id="vcomments" class="blog-post-comments"></div>
    <script>
        new Valine({
            el: '#vcomments',
            visitor: true,
            appId: 'q494NdCTA7S8AuwxLVHFxz41-MdYXbMMI',
            appKey: 'dV8G37HkOGPbWVkPzlAUndh7',
            placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
            avatar: 'robohash'
        })
    </script>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">Tag</a></li>
         
          <li><a href="/categories/">Category</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-线性回归"><span class="toc-number">1.</span> <span class="toc-text">1.线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-逻辑回归"><span class="toc-number">2.</span> <span class="toc-text">2. 逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#改进模型"><span class="toc-number">2.0.1.</span> <span class="toc-text">改进模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-决策树"><span class="toc-number">3.</span> <span class="toc-text">3. 决策树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-支持向量机"><span class="toc-number">4.</span> <span class="toc-text">4. 支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-朴素贝叶斯"><span class="toc-number">5.</span> <span class="toc-text">5. 朴素贝叶斯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-kNN-k最近邻"><span class="toc-number">6.</span> <span class="toc-text">6. kNN(k最近邻)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-k-均值"><span class="toc-number">7.</span> <span class="toc-text">7. k-均值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-随机森林"><span class="toc-number">8.</span> <span class="toc-text">8. 随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-降维算法"><span class="toc-number">9.</span> <span class="toc-text">9. 降维算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-梯度提升算法"><span class="toc-number">10.</span> <span class="toc-text">10.梯度提升算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#10-1-GBM"><span class="toc-number">10.1.</span> <span class="toc-text">10.1 GBM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-2-XGBoost"><span class="toc-number">10.2.</span> <span class="toc-text">10.2 XGBoost</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-3-LightGBM"><span class="toc-number">10.3.</span> <span class="toc-text">10.3 LightGBM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-4-Catboost"><span class="toc-number">10.4.</span> <span class="toc-text">10.4 Catboost</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Reference"><span class="toc-number">10.5.</span> <span class="toc-text">Reference:</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&text=机器学习常用算法"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&is_video=false&description=机器学习常用算法"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=机器学习常用算法&body=Check out this article: https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&title=机器学习常用算法"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/06/机器学习常用算法/&name=机器学习常用算法&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2020 Robby
    <a href="http://www.beian.miit.gov.cn/">豫ICP备19040301号</a> 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">Tag</a></li>
         
          <li><a href="/categories/">Category</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
        
    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-148159204-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?dbb105d46eafbe9b2400ee1886ae06d2";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


</body>
</html>
