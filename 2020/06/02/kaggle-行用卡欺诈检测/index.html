<!DOCTYPE html>
<html lang=en>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="我们的目标1.理解提供给我们的“少量”数据的少量分布2.创建“欺诈”和“非欺诈”交易的50/50子数据帧比率。(NearMiss Algorithm)3.确定我们将要使用的分类器，并确定哪一个具有更高的准确性。4.创建一个神经网络并将准确性与我们最好的分类器进行比较。5.了解不平衡数据集的常见错误。 大纲 理解我们的数据1） 收集数据  预处理1） 缩放和分布2） 切割数据   3.随机欠采样和过">
<meta name="keywords" content="kaggle,分类">
<meta property="og:type" content="article">
<meta property="og:title" content="kaggle_行用卡欺诈检测">
<meta property="og:url" content="https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/index.html">
<meta property="og:site_name" content="Robby">
<meta property="og:description" content="我们的目标1.理解提供给我们的“少量”数据的少量分布2.创建“欺诈”和“非欺诈”交易的50/50子数据帧比率。(NearMiss Algorithm)3.确定我们将要使用的分类器，并确定哪一个具有更高的准确性。4.创建一个神经网络并将准确性与我们最好的分类器进行比较。5.了解不平衡数据集的常见错误。 大纲 理解我们的数据1） 收集数据  预处理1） 缩放和分布2） 切割数据   3.随机欠采样和过">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://github.com/gaojianjie412/gaojianjie412.github.io/2020/Downloads/credit_card/output_12_1.png">
<meta property="og:image" content="http://qiniu.robbyml.com/output_13_0.png">
<meta property="og:image" content="http://qiniu.robbyml.com/output_25_1.png">
<meta property="og:updated_time" content="2020-06-01T16:14:04.275Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kaggle_行用卡欺诈检测">
<meta name="twitter:description" content="我们的目标1.理解提供给我们的“少量”数据的少量分布2.创建“欺诈”和“非欺诈”交易的50/50子数据帧比率。(NearMiss Algorithm)3.确定我们将要使用的分类器，并确定哪一个具有更高的准确性。4.创建一个神经网络并将准确性与我们最好的分类器进行比较。5.了解不平衡数据集的常见错误。 大纲 理解我们的数据1） 收集数据  预处理1） 缩放和分布2） 切割数据   3.随机欠采样和过">
<meta name="twitter:image" content="https://github.com/gaojianjie412/gaojianjie412.github.io/2020/Downloads/credit_card/output_12_1.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>kaggle_行用卡欺诈检测</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">Tag</a></li>
         
          <li><a href="/categories/">Category</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        
        <li><a class="icon" href="/2020/05/30/04-零基础入门CV-模型训练与验证/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&text=kaggle_行用卡欺诈检测"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&is_video=false&description=kaggle_行用卡欺诈检测"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=kaggle_行用卡欺诈检测&body=Check out this article: https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&name=kaggle_行用卡欺诈检测&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#我们的目标"><span class="toc-number">1.</span> <span class="toc-text">我们的目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#大纲"><span class="toc-number">2.</span> <span class="toc-text">大纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#从不平衡的数据集中纠正先前的错误"><span class="toc-number">3.</span> <span class="toc-text">从不平衡的数据集中纠正先前的错误</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#收集数据"><span class="toc-number"></span> <span class="toc-text">收集数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#摘要"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征技术"><span class="toc-number">2.</span> <span class="toc-text">特征技术</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#缩放和分布"><span class="toc-number"></span> <span class="toc-text">缩放和分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#切分数据"><span class="toc-number"></span> <span class="toc-text">切分数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#随机欠采样"><span class="toc-number"></span> <span class="toc-text">随机欠采样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#均匀分布和相关性"><span class="toc-number"></span> <span class="toc-text">均匀分布和相关性</span></a>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        kaggle_行用卡欺诈检测
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Robby</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-06-01T16:11:11.000Z" itemprop="datePublished">2020-06-02</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/kaggle/">kaggle</a>, <a class="tag-link" href="/tags/分类/">分类</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h3 id="我们的目标"><a href="#我们的目标" class="headerlink" title="我们的目标"></a>我们的目标</h3><p>1.理解提供给我们的“少量”数据的少量分布<br>2.创建“欺诈”和“非欺诈”交易的50/50子数据帧比率。(NearMiss Algorithm)<br>3.确定我们将要使用的分类器，并确定哪一个具有更高的准确性。<br>4.创建一个神经网络并将准确性与我们最好的分类器进行比较。<br>5.了解不平衡数据集的常见错误。</p>
<h3 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h3><ol>
<li><p>理解我们的数据<br>1） 收集数据</p>
</li>
<li><p>预处理<br>1） 缩放和分布<br>2） 切割数据</p>
</li>
</ol>
<p>3.随机欠采样和过采样<br>    1）分布和相关性<br>    2）异常检测<br>    3）降维和聚类（t-SNE）<br>    4）分类器<br>    5）深入研究逻辑回归<br>    6）使用SMOTE过采样</p>
<p>4.测试<br>    1）使用逻辑回归测试<br>    2）神经网络测试（欠采样VS过采样）</p>
<h3 id="从不平衡的数据集中纠正先前的错误"><a href="#从不平衡的数据集中纠正先前的错误" class="headerlink" title="从不平衡的数据集中纠正先前的错误"></a>从不平衡的数据集中纠正先前的错误</h3><ol>
<li>切勿对过采样或欠采样的数据集进行测试</li>
<li>如果我们要实施交叉验证，请记住在交叉验证期间而不是之前对训练数据进行过度采样或欠采样！</li>
<li>不要将准确率得分用作不平衡数据集的度量标准（通常会很高并且容易误导），而应使用f1-score，precision/recall score或 混淆矩阵</li>
</ol>
<h2 id="收集数据"><a href="#收集数据" class="headerlink" title="收集数据"></a>收集数据</h2><p>我们要做的第一件事是收集数据的基本知识。请记住，除了transaction和amount，我们不知道其他列是什么（由于隐私原因）。我们唯一知道的是，那些未知的列已经被缩放。</p>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>1.交易金额相对较小。所有交易金额的平均值约为88美元。<br>2.没有“Null”值，因此我们不必研究替换值的方法。<br>3.大多数交易是非欺诈（99.83％），而欺诈交易（017％）发生在数据帧中。</p>
<h3 id="特征技术"><a href="#特征技术" class="headerlink" title="特征技术"></a>特征技术</h3><ol>
<li>PCA转型：数据描述表明，所有特征都经过了PCA转换（降维技术）（时间和数量除外）。</li>
<li>缩放：请记住，为了实现PCA转换特征，需要预先缩放。 （在这种情况下，所有V特征都已缩放，或者至少这是我们假设开发数据集的人员所做的。）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Imported Libraries</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA, TruncatedSVD</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> mpatches</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># Classifier Libraries</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Other Libraries</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> make_pipeline</span><br><span class="line"><span class="keyword">from</span> imblearn.pipeline <span class="keyword">import</span> make_pipeline <span class="keyword">as</span> imbalanced_make_pipeline</span><br><span class="line"><span class="comment"># imblearn 数据不平衡处理库</span></span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> NearMiss</span><br><span class="line"><span class="keyword">from</span> imblearn.metrics <span class="keyword">import</span> classification_report_imbalanced</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, StratifiedKFold</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'../input/creditcard.csv'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>

</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.describe()</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>284807.000000</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>...</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>284807.000000</td>
      <td>284807.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94813.859575</td>
      <td>1.165980e-15</td>
      <td>3.416908e-16</td>
      <td>-1.373150e-15</td>
      <td>2.086869e-15</td>
      <td>9.604066e-16</td>
      <td>1.490107e-15</td>
      <td>-5.556467e-16</td>
      <td>1.177556e-16</td>
      <td>-2.406455e-15</td>
      <td>...</td>
      <td>1.656562e-16</td>
      <td>-3.444850e-16</td>
      <td>2.578648e-16</td>
      <td>4.471968e-15</td>
      <td>5.340915e-16</td>
      <td>1.687098e-15</td>
      <td>-3.666453e-16</td>
      <td>-1.220404e-16</td>
      <td>88.349619</td>
      <td>0.001727</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47488.145955</td>
      <td>1.958696e+00</td>
      <td>1.651309e+00</td>
      <td>1.516255e+00</td>
      <td>1.415869e+00</td>
      <td>1.380247e+00</td>
      <td>1.332271e+00</td>
      <td>1.237094e+00</td>
      <td>1.194353e+00</td>
      <td>1.098632e+00</td>
      <td>...</td>
      <td>7.345240e-01</td>
      <td>7.257016e-01</td>
      <td>6.244603e-01</td>
      <td>6.056471e-01</td>
      <td>5.212781e-01</td>
      <td>4.822270e-01</td>
      <td>4.036325e-01</td>
      <td>3.300833e-01</td>
      <td>250.120109</td>
      <td>0.041527</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-5.640751e+01</td>
      <td>-7.271573e+01</td>
      <td>-4.832559e+01</td>
      <td>-5.683171e+00</td>
      <td>-1.137433e+02</td>
      <td>-2.616051e+01</td>
      <td>-4.355724e+01</td>
      <td>-7.321672e+01</td>
      <td>-1.343407e+01</td>
      <td>...</td>
      <td>-3.483038e+01</td>
      <td>-1.093314e+01</td>
      <td>-4.480774e+01</td>
      <td>-2.836627e+00</td>
      <td>-1.029540e+01</td>
      <td>-2.604551e+00</td>
      <td>-2.256568e+01</td>
      <td>-1.543008e+01</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54201.500000</td>
      <td>-9.203734e-01</td>
      <td>-5.985499e-01</td>
      <td>-8.903648e-01</td>
      <td>-8.486401e-01</td>
      <td>-6.915971e-01</td>
      <td>-7.682956e-01</td>
      <td>-5.540759e-01</td>
      <td>-2.086297e-01</td>
      <td>-6.430976e-01</td>
      <td>...</td>
      <td>-2.283949e-01</td>
      <td>-5.423504e-01</td>
      <td>-1.618463e-01</td>
      <td>-3.545861e-01</td>
      <td>-3.171451e-01</td>
      <td>-3.269839e-01</td>
      <td>-7.083953e-02</td>
      <td>-5.295979e-02</td>
      <td>5.600000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84692.000000</td>
      <td>1.810880e-02</td>
      <td>6.548556e-02</td>
      <td>1.798463e-01</td>
      <td>-1.984653e-02</td>
      <td>-5.433583e-02</td>
      <td>-2.741871e-01</td>
      <td>4.010308e-02</td>
      <td>2.235804e-02</td>
      <td>-5.142873e-02</td>
      <td>...</td>
      <td>-2.945017e-02</td>
      <td>6.781943e-03</td>
      <td>-1.119293e-02</td>
      <td>4.097606e-02</td>
      <td>1.659350e-02</td>
      <td>-5.213911e-02</td>
      <td>1.342146e-03</td>
      <td>1.124383e-02</td>
      <td>22.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139320.500000</td>
      <td>1.315642e+00</td>
      <td>8.037239e-01</td>
      <td>1.027196e+00</td>
      <td>7.433413e-01</td>
      <td>6.119264e-01</td>
      <td>3.985649e-01</td>
      <td>5.704361e-01</td>
      <td>3.273459e-01</td>
      <td>5.971390e-01</td>
      <td>...</td>
      <td>1.863772e-01</td>
      <td>5.285536e-01</td>
      <td>1.476421e-01</td>
      <td>4.395266e-01</td>
      <td>3.507156e-01</td>
      <td>2.409522e-01</td>
      <td>9.104512e-02</td>
      <td>7.827995e-02</td>
      <td>77.165000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172792.000000</td>
      <td>2.454930e+00</td>
      <td>2.205773e+01</td>
      <td>9.382558e+00</td>
      <td>1.687534e+01</td>
      <td>3.480167e+01</td>
      <td>7.330163e+01</td>
      <td>1.205895e+02</td>
      <td>2.000721e+01</td>
      <td>1.559499e+01</td>
      <td>...</td>
      <td>2.720284e+01</td>
      <td>1.050309e+01</td>
      <td>2.252841e+01</td>
      <td>4.584549e+00</td>
      <td>7.519589e+00</td>
      <td>3.517346e+00</td>
      <td>3.161220e+01</td>
      <td>3.384781e+01</td>
      <td>25691.160000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>

</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.isnull().sum()</span><br></pre></td></tr></table></figure>

<pre><code>Time      0
V1        0
V2        0
V3        0
V4        0
V5        0
V6        0
V7        0
V8        0
V9        0
V10       0
V11       0
V12       0
V13       0
V14       0
V15       0
V16       0
V17       0
V18       0
V19       0
V20       0
V21       0
V22       0
V23       0
V24       0
V25       0
V26       0
V27       0
V28       0
Amount    0
Class     0
dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.isnull().sum().max()</span><br></pre></td></tr></table></figure>

<pre><code>0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.columns</span><br></pre></td></tr></table></figure>

<pre><code>Index([&apos;Time&apos;, &apos;V1&apos;, &apos;V2&apos;, &apos;V3&apos;, &apos;V4&apos;, &apos;V5&apos;, &apos;V6&apos;, &apos;V7&apos;, &apos;V8&apos;, &apos;V9&apos;, &apos;V10&apos;,
       &apos;V11&apos;, &apos;V12&apos;, &apos;V13&apos;, &apos;V14&apos;, &apos;V15&apos;, &apos;V16&apos;, &apos;V17&apos;, &apos;V18&apos;, &apos;V19&apos;, &apos;V20&apos;,
       &apos;V21&apos;, &apos;V22&apos;, &apos;V23&apos;, &apos;V24&apos;, &apos;V25&apos;, &apos;V26&apos;, &apos;V27&apos;, &apos;V28&apos;, &apos;Amount&apos;,
       &apos;Class&apos;],
      dtype=&apos;object&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
RangeIndex: 284807 entries, 0 to 284806
Data columns (total 31 columns):
 #   Column  Non-Null Count   Dtype  
---  ------  --------------   -----  
 0   Time    284807 non-null  float64
 1   V1      284807 non-null  float64
 2   V2      284807 non-null  float64
 3   V3      284807 non-null  float64
 4   V4      284807 non-null  float64
 5   V5      284807 non-null  float64
 6   V6      284807 non-null  float64
 7   V7      284807 non-null  float64
 8   V8      284807 non-null  float64
 9   V9      284807 non-null  float64
 10  V10     284807 non-null  float64
 11  V11     284807 non-null  float64
 12  V12     284807 non-null  float64
 13  V13     284807 non-null  float64
 14  V14     284807 non-null  float64
 15  V15     284807 non-null  float64
 16  V16     284807 non-null  float64
 17  V17     284807 non-null  float64
 18  V18     284807 non-null  float64
 19  V19     284807 non-null  float64
 20  V20     284807 non-null  float64
 21  V21     284807 non-null  float64
 22  V22     284807 non-null  float64
 23  V23     284807 non-null  float64
 24  V24     284807 non-null  float64
 25  V25     284807 non-null  float64
 26  V26     284807 non-null  float64
 27  V27     284807 non-null  float64
 28  V28     284807 non-null  float64
 29  Amount  284807 non-null  float64
 30  Class   284807 non-null  int64  
dtypes: float64(30), int64(1)
memory usage: 67.4 MB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 类别严重不平衡，一会在进行处理</span></span><br><span class="line">print(<span class="string">'No Frauds:'</span>,round(df[<span class="string">'Class'</span>].value_counts()[<span class="number">0</span>]/len(df)*<span class="number">100</span>,<span class="number">2</span>),<span class="string">'% of the dataset'</span>)</span><br><span class="line">print(<span class="string">'Frauds:'</span>,round(df[<span class="string">'Class'</span>].value_counts()[<span class="number">1</span>]/len(df)*<span class="number">100</span>,<span class="number">2</span>),<span class="string">'% of the dataset'</span>)</span><br></pre></td></tr></table></figure>

<pre><code>No Frauds: 99.83 % of the dataset
Frauds: 0.17 % of the dataset</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">colors = [<span class="string">'#DF0101'</span>,<span class="string">'#0101DF'</span>]</span><br><span class="line"></span><br><span class="line">sns.countplot(<span class="string">'Class'</span>, data=df, palette=colors)</span><br><span class="line">plt.title(<span class="string">'Class Distributions \n (0: No Fraud || 1: Fraud)'</span>, fontsize=<span class="number">14</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Text(0.5, 1.0, &apos;Class Distributions \n (0: No Fraud || 1: Fraud)&apos;)</code></pre><p><img src="../../../Downloads/credit_card/output_12_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sns.set(font='SimHei')</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">18</span>,<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">amount_val = df[<span class="string">'Amount'</span>].values</span><br><span class="line">time_val = df[<span class="string">'Time'</span>].values</span><br><span class="line"></span><br><span class="line">sns.distplot(amount_val, ax=ax[<span class="number">0</span>],color=<span class="string">'r'</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'数量的趋势'</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_xlim([min(amount_val), max(amount_val)])</span><br><span class="line"><span class="comment"># 切片</span></span><br><span class="line"></span><br><span class="line">sns.distplot(time_val, ax=ax[<span class="number">1</span>], color=<span class="string">'b'</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'时间的趋势'</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_xlim([min(time_val),max(time_val)])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.robbyml.com/output_13_0.png" alt></p>
<h2 id="缩放和分布"><a href="#缩放和分布" class="headerlink" title="缩放和分布"></a>缩放和分布</h2><p>我们将首先缩放由Time和Amount组成的列。时间和数量应与其他列一样缩放。另一方面，我们还需要创建数据帧的子样本，<br>以使欺诈和非欺诈案件数量相等，从而帮助我们的算法更好地理解确定交易是否为欺诈行为的模式。</p>
<p>在这种情况下，我们的子样本将是一个欺诈和非欺诈交易比率为50/50的数据框。意味着我们的子样本将具有相同数量的欺诈和非欺诈交易。</p>
<p>为什么要创建子样本？？？？？<br>1.过拟合：我们的分类模型将设想在大多数情况下没有欺诈！我们希望我们的模型能够确定何时发生欺诈。<br>2.错的相关性：尽管我们不知道“ V”特征代表什么，无法看到’class’与特征之间的真实相关性，但了解每个特征如何通过不平衡数据帧影响结果（欺诈或无欺诈）将非常有用</p>
<p>摘要：<br>1.scaled amount和sacled time 应该使用scaled values<br>2.我们的数据集中有492个欺诈案件，因此我们可以随机获得492个非欺诈案件来创建新的子数据dataframe。<br>3.我们合并了492个欺诈和非欺诈案例，创建了一个新的子样本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 缩放数据</span></span><br><span class="line"><span class="comment"># StandardScaler 去均值和方差归一化</span></span><br><span class="line"><span class="comment"># robustscaler 数据中异常值，均差和方差标准化不好，使用这个</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, RobustScaler</span><br><span class="line"></span><br><span class="line">std_scaler = StandardScaler()</span><br><span class="line">rob_scaler = RobustScaler()</span><br><span class="line"></span><br><span class="line">df[<span class="string">'scaled_amount'</span>] = rob_scaler.fit_transform(df[<span class="string">'Amount'</span>].values.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line">df[<span class="string">'scaled_time'</span>] = rob_scaler.fit_transform(df[<span class="string">'Time'</span>].values.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">df.drop([<span class="string">'Time'</span>,<span class="string">'Amount'</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># axis=0代表往跨行（down)，而axis=1代表跨列（across)</span></span><br><span class="line"><span class="comment"># 第0轴沿着行的垂直往下，第1轴沿着列的方向水平延伸。</span></span><br></pre></td></tr></table></figure>

<pre><code>---------------------------------------------------------------------------

KeyError                                  Traceback (most recent call last)

~/opt/anaconda3/envs/analysis/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)
   2645             try:
-&gt; 2646                 return self._engine.get_loc(key)
   2647             except KeyError:


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


KeyError: &apos;Amount&apos;</code></pre><p>​    </p>
<pre><code>During handling of the above exception, another exception occurred:


KeyError                                  Traceback (most recent call last)

&lt;ipython-input-54-56912ef63763&gt; in &lt;module&gt;
      7 rob_scaler = RobustScaler()
      8 
----&gt; 9 df[&apos;scaled_amount&apos;] = rob_scaler.fit_transform(df[&apos;Amount&apos;].values.reshape(-1,1))
     10 df[&apos;scaled_time&apos;] = rob_scaler.fit_transform(df[&apos;Time&apos;].values.reshape(-1,1))
     11 


~/opt/anaconda3/envs/analysis/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key)
   2798             if self.columns.nlevels &gt; 1:
   2799                 return self._getitem_multilevel(key)
-&gt; 2800             indexer = self.columns.get_loc(key)
   2801             if is_integer(indexer):
   2802                 indexer = [indexer]


~/opt/anaconda3/envs/analysis/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)
   2646                 return self._engine.get_loc(key)
   2647             except KeyError:
-&gt; 2648                 return self._engine.get_loc(self._maybe_cast_indexer(key))
   2649         indexer = self.get_indexer([key], method=method, tolerance=tolerance)
   2650         if indexer.ndim &gt; 1 or indexer.size &gt; 1:


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


KeyError: &apos;Amount&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scaled_amount = df[<span class="string">'scaled_amount'</span>]</span><br><span class="line">scaled_time = df[<span class="string">'scaled_time'</span>]</span><br><span class="line"></span><br><span class="line">df.drop([<span class="string">'scaled_amount'</span>, <span class="string">'scaled_time'</span>], axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">df.insert(<span class="number">0</span>, <span class="string">'scaled_amount'</span>, scaled_amount)</span><br><span class="line">df.insert(<span class="number">1</span>, <span class="string">'scaled_time'</span>, scaled_time)</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<pre><code>---------------------------------------------------------------------------

KeyError                                  Traceback (most recent call last)

~/opt/anaconda3/envs/analysis/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)
   2645             try:
-&gt; 2646                 return self._engine.get_loc(key)
   2647             except KeyError:


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


KeyError: &apos;scaled_amount&apos;</code></pre><p>​    </p>
<pre><code>During handling of the above exception, another exception occurred:


KeyError                                  Traceback (most recent call last)

&lt;ipython-input-58-18620eed030e&gt; in &lt;module&gt;
----&gt; 1 scaled_amount = df[&apos;scaled_amount&apos;]
      2 scaled_time = df[&apos;scaled_time&apos;]
      3 
      4 df.drop([&apos;scaled_amount&apos;, &apos;scaled_time&apos;], axis=1,inplace=True)
      5 df.insert(0, &apos;scaled_amount&apos;, scaled_amount)


~/opt/anaconda3/envs/analysis/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key)
   2798             if self.columns.nlevels &gt; 1:
   2799                 return self._getitem_multilevel(key)
-&gt; 2800             indexer = self.columns.get_loc(key)
   2801             if is_integer(indexer):
   2802                 indexer = [indexer]


~/opt/anaconda3/envs/analysis/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)
   2646                 return self._engine.get_loc(key)
   2647             except KeyError:
-&gt; 2648                 return self._engine.get_loc(self._maybe_cast_indexer(key))
   2649         indexer = self.get_indexer([key], method=method, tolerance=tolerance)
   2650         if indexer.ndim &gt; 1 or indexer.size &gt; 1:


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()


KeyError: &apos;scaled_amount&apos;</code></pre><h2 id="切分数据"><a href="#切分数据" class="headerlink" title="切分数据"></a>切分数据</h2><p>在继续进行随机欠采样技术之前，我们必须分离原始数据帧。为什么？出于测试目的，请记住，尽管我们在实施随机欠采样或过采样技术时会拆分数据，<br>但我们希望在原始测试集上测试模型，而不是在这两种技术中创建的测试集上测试模型。主要目标是使用欠采样和过采样的数据框来拟合模型<br>（以使我们的模型能够检测到模式），并在原始测试集上进行测试</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"></span><br><span class="line">print(<span class="string">'No Fraudd'</span>, round(df[<span class="string">'Class'</span>].value_counts()[<span class="number">0</span>]/len(df) * <span class="number">100</span>,<span class="number">2</span>), <span class="string">'% of the dataset'</span>)</span><br><span class="line">print(<span class="string">'Fraudd'</span>, round(df[<span class="string">'Class'</span>].value_counts()[<span class="number">1</span>]/len(df) * <span class="number">100</span>,<span class="number">2</span>), <span class="string">'% of the dataset'</span>)</span><br><span class="line"></span><br><span class="line">X = df.drop(<span class="string">'Class'</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">'Class'</span>]</span><br><span class="line"></span><br><span class="line">sss = StratifiedKFold(n_splits=<span class="number">5</span>, random_state=<span class="literal">None</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> sss.split(X, y):</span><br><span class="line">    print(<span class="string">'Train:'</span>, train_index, <span class="string">'Test:'</span>, test_index)</span><br><span class="line">    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]</span><br><span class="line">    <span class="comment"># 训练集与验证集</span></span><br><span class="line">    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]</span><br><span class="line">    <span class="comment"># 训练集与验证集的标签</span></span><br><span class="line">    <span class="comment">#对于欠采样数据，我们已经有了X_train和y_train，这就是为什么我使用原始格式来区分而不覆盖这些变量的原因。</span></span><br></pre></td></tr></table></figure>

<pre><code>No Fraudd 99.83 % of the dataset
Fraudd 0.17 % of the dataset
Train: [ 30473  30496  31002 ... 284804 284805 284806] Test: [    0     1     2 ... 57017 57018 57019]
Train: [     0      1      2 ... 284804 284805 284806] Test: [ 30473  30496  31002 ... 113964 113965 113966]
Train: [     0      1      2 ... 284804 284805 284806] Test: [ 81609  82400  83053 ... 170946 170947 170948]
Train: [     0      1      2 ... 284804 284805 284806] Test: [150654 150660 150661 ... 227866 227867 227868]
Train: [     0      1      2 ... 227866 227867 227868] Test: [212516 212644 213092 ... 284804 284805 284806]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 变成数组</span></span><br><span class="line">original_Xtrain = original_Xtrain.values</span><br><span class="line">original_Xtest = original_Xtest.values</span><br><span class="line">original_ytrain = original_ytrain.values</span><br><span class="line">original_ytest = original_ytest.values</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看训练和测试标签的分布是否都相似</span></span><br><span class="line">train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#np.unique去除重复的元素，return_counts=True返回各个元素的出现的次数</span></span><br><span class="line">test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=<span class="literal">True</span>)</span><br><span class="line">print(<span class="string">'-'</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'标签的分布情况: \n'</span>)</span><br><span class="line">print(train_counts_label/len(original_ytrain))</span><br><span class="line">print(test_counts_label/ len(original_ytest))</span><br></pre></td></tr></table></figure>

<pre><code>----------------------------------------------------------------------------------------------------
标签的分布情况: 

[0.99827076 0.00172924]
[0.99827952 0.00172048]</code></pre><h2 id="随机欠采样"><a href="#随机欠采样" class="headerlink" title="随机欠采样"></a>随机欠采样</h2><p>我们将实施“随机抽样”，该过程主要包括删除数据，以使数据集更加平衡，从而避免模型过度拟合。</p>
<p>###步骤：</p>
<p>1.我们要做的第一件事是定义class的不平衡程度（在class列上使用“ value_counts（）”来确定每个标签的数量）<br>2.一旦确定了多少个实例被视为欺诈交易（Fraud =“ 1”），我们就应将非欺诈交易的数量与欺诈交易的数量相同（假设我们想要50/50的比率），<br>这将等于492欺诈案件和492个非欺诈交易案件。<br>3.实施此技术后，关于class我们的数据帧有一个子样本，该子样本的比率为50/50。然后，我们将实现的下一步是重新整理数据，<br>以查看每次运行此脚本时我们的模型是否都能保持一定的准确性。</p>
<p>###提示：</p>
<p>“随机欠采样”的主要问题是，由于存在大量信息丢失，我们冒着分类模型无法像我们想要的那样准确运行的风险<br>（从284315个非欺诈交易中带来了492个非欺诈交易）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于‘Class’高度偏斜，因此我们应该使它们等效，以使其具有正态分布</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 让我们在创建子样本之前先对数据进行混洗</span></span><br><span class="line"><span class="comment"># DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)</span></span><br><span class="line"><span class="comment"># n是要抽取的行数。（例如n=20000时，抽取其中的2W行）</span></span><br><span class="line"><span class="comment">#frac是抽取的比例。（有一些时候，我们并对具体抽取的行数不关系，我们想抽取其中的百分比，这个时候就可以选择使用frac，例如frac=0.8，就是抽取其中80%）</span></span><br><span class="line"><span class="comment">#replace：是否为有放回抽样，取replace=True时为有放回抽样。</span></span><br><span class="line"><span class="comment">#weights这个是每个样本的权重，具体可以看官方文档说明。</span></span><br><span class="line"><span class="comment"># random_state 随机数发生器种子，random_state=None取得数据不重复，random_state=1可以取得重复数据</span></span><br><span class="line"><span class="comment">#axis是选择抽取数据的行还是列。axis=0的时是抽取行，axis=1时是抽取列（也就是说axis=1时，在列中随机抽取n列，在axis=0时，在行中随机抽取n行）</span></span><br><span class="line">df = df.sample(frac=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 欺诈class数量492行</span></span><br><span class="line">fraud_df = df.loc[df[<span class="string">'Class'</span>]==<span class="number">1</span>]</span><br><span class="line">non_fraud_df = df.loc[df[<span class="string">'Class'</span>]==<span class="number">0</span>][:<span class="number">492</span>]</span><br><span class="line"></span><br><span class="line">normal_distributed_df = pd.concat([fraud_df, non_fraud_df])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新整理dataframe行</span></span><br><span class="line">new_df = normal_distributed_df.sample(frac=<span class="number">1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">new_df.head()</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>135267</th>
      <td>-1.964803</td>
      <td>1.919102</td>
      <td>-0.291021</td>
      <td>-1.039460</td>
      <td>-0.341769</td>
      <td>-0.006325</td>
      <td>-0.478555</td>
      <td>1.485774</td>
      <td>-0.287057</td>
      <td>-0.542559</td>
      <td>...</td>
      <td>-0.004290</td>
      <td>-0.163627</td>
      <td>-0.593631</td>
      <td>-0.089858</td>
      <td>-1.022412</td>
      <td>0.106808</td>
      <td>0.376165</td>
      <td>0.130812</td>
      <td>0.089531</td>
      <td>0</td>
    </tr>
    <tr>
      <th>243393</th>
      <td>-5.488032</td>
      <td>3.329561</td>
      <td>-5.996296</td>
      <td>3.601720</td>
      <td>-2.023926</td>
      <td>-1.737393</td>
      <td>-4.396859</td>
      <td>0.228394</td>
      <td>-1.675884</td>
      <td>-3.991785</td>
      <td>...</td>
      <td>-0.551121</td>
      <td>1.719631</td>
      <td>0.343209</td>
      <td>0.133584</td>
      <td>0.833340</td>
      <td>-0.839776</td>
      <td>0.502010</td>
      <td>-1.937473</td>
      <td>1.521218</td>
      <td>1</td>
    </tr>
    <tr>
      <th>58234</th>
      <td>1.035703</td>
      <td>-0.610911</td>
      <td>0.846273</td>
      <td>-0.836050</td>
      <td>-0.965309</td>
      <td>0.035398</td>
      <td>-0.636706</td>
      <td>0.176490</td>
      <td>1.431925</td>
      <td>-1.005319</td>
      <td>...</td>
      <td>0.054235</td>
      <td>0.267575</td>
      <td>0.951040</td>
      <td>-0.185119</td>
      <td>0.086438</td>
      <td>0.532460</td>
      <td>-0.528689</td>
      <td>0.101958</td>
      <td>0.032799</td>
      <td>0</td>
    </tr>
    <tr>
      <th>43681</th>
      <td>-18.247513</td>
      <td>8.713250</td>
      <td>-17.880127</td>
      <td>9.249459</td>
      <td>-14.541213</td>
      <td>-1.911564</td>
      <td>-18.014660</td>
      <td>5.522162</td>
      <td>-9.283925</td>
      <td>-14.557159</td>
      <td>...</td>
      <td>-0.526368</td>
      <td>0.598843</td>
      <td>0.615319</td>
      <td>-0.486499</td>
      <td>0.739268</td>
      <td>-0.236845</td>
      <td>-0.046082</td>
      <td>-3.011473</td>
      <td>-1.022147</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8842</th>
      <td>-4.696795</td>
      <td>2.693867</td>
      <td>-4.475133</td>
      <td>5.467685</td>
      <td>-1.556758</td>
      <td>-1.549420</td>
      <td>-4.104215</td>
      <td>0.553934</td>
      <td>-1.498468</td>
      <td>-4.594952</td>
      <td>...</td>
      <td>-0.158971</td>
      <td>0.573898</td>
      <td>-0.080163</td>
      <td>0.318408</td>
      <td>-0.245862</td>
      <td>0.338238</td>
      <td>0.032271</td>
      <td>-1.508458</td>
      <td>0.608075</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 29 columns</p>

</div>



<h2 id="均匀分布和相关性"><a href="#均匀分布和相关性" class="headerlink" title="均匀分布和相关性"></a>均匀分布和相关性</h2><p>现在我们已经正确平衡了数据，我们可以进一步进行分析和数据预处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Class 在子数据集中的分布'</span>)</span><br><span class="line">print(new_df[<span class="string">'Class'</span>].value_counts()/len(new_df))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sns.countplot(<span class="string">'Class'</span>, data=new_df, palette=colors)</span><br><span class="line">plt.title(<span class="string">'Class的均匀分布'</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Class 在子数据集中的分布
1    0.5
0    0.5
Name: Class, dtype: float64</code></pre><p><img src="http://qiniu.robbyml.com/output_25_1.png" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 相关矩阵</span></span><br></pre></td></tr></table></figure>
  </div>
</article>



    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
    <div id="vcomments" class="blog-post-comments"></div>
    <script>
        new Valine({
            el: '#vcomments',
            visitor: true,
            appId: 'q494NdCTA7S8AuwxLVHFxz41-MdYXbMMI',
            appKey: 'dV8G37HkOGPbWVkPzlAUndh7',
            placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
            avatar: 'robohash'
        })
    </script>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">Tag</a></li>
         
          <li><a href="/categories/">Category</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#我们的目标"><span class="toc-number">1.</span> <span class="toc-text">我们的目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#大纲"><span class="toc-number">2.</span> <span class="toc-text">大纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#从不平衡的数据集中纠正先前的错误"><span class="toc-number">3.</span> <span class="toc-text">从不平衡的数据集中纠正先前的错误</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#收集数据"><span class="toc-number"></span> <span class="toc-text">收集数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#摘要"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征技术"><span class="toc-number">2.</span> <span class="toc-text">特征技术</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#缩放和分布"><span class="toc-number"></span> <span class="toc-text">缩放和分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#切分数据"><span class="toc-number"></span> <span class="toc-text">切分数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#随机欠采样"><span class="toc-number"></span> <span class="toc-text">随机欠采样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#均匀分布和相关性"><span class="toc-number"></span> <span class="toc-text">均匀分布和相关性</span></a>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&text=kaggle_行用卡欺诈检测"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&is_video=false&description=kaggle_行用卡欺诈检测"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=kaggle_行用卡欺诈检测&body=Check out this article: https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&title=kaggle_行用卡欺诈检测"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://github.com/gaojianjie412/gaojianjie412.github.io/2020/06/02/kaggle-行用卡欺诈检测/&name=kaggle_行用卡欺诈检测&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2020 Robby
    <a href="http://www.beian.miit.gov.cn/">豫ICP备19040301号</a> 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">Tag</a></li>
         
          <li><a href="/categories/">Category</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
        
    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-148159204-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?dbb105d46eafbe9b2400ee1886ae06d2";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


</body>
</html>
